\documentclass{juliacon}
\setcounter{page}{1}

\usepackage{cleveref}
\crefformat{footnote}{#2\footnotemark[#1]#3}

\begin{document}

\input{header}

\maketitle

\begin{abstract}

Arithmetic operations defined in Julia do not modify their arguments.
However, in many situations, a variable represents an accumulator that can be modified in-place to contain the result, e.g., when summing the elements of an array.
Moreover, for types that support mutation, mutating the value may have a significant performance benefit over creating a new instance.
This talk presents an interface that allows algorithms to exploit mutability in arithmetic operations in a generic manner.

\end{abstract}

\section{Introduction}

Julia enables generic algorithms that work with arbitrary number types, as long as the types implement the needed operations
such as \texttt{+}, \texttt{*}, \texttt{-}, \texttt{zero}, \texttt{one}, ...
The implementations of these arithmetic operations in Julia do not modify their arguments. Instead, they return a new instance of the type as the result.
However, in many situations, a variable represents an accumulator that can be modified to contain the result, e.g.,
when summing the elements of an array or when implementing array multiplication.
Moreover, for types that support mutation, mutating the value may have a significant performance benefit over creating a new instance.
Examples of types that implement arithmetic operations and support mutation are \texttt{Array}s, multiple precision numbers, JuMP~\cite{dunning2017jump} expressions, MathOptInterface (MOI)~\cite{legat2021mathoptinterface} functions, and polynomials (multivariate~\cite{legat2021multivariatepolynomials} or univariate).

This paper introduces an interface called MutableArithmetics (MA).
It allows mutable types to implement an arithmetic exploiting their mutability, and for algorithms to
exploit their mutability while remaining completely generic.
Moreover, it provides the following additional features:
\begin{enumerate}
  \item
    \label{item:reimplement}
    it re-implements part of the Julia standard library on top of the API to allow mutable types to use a more efficient version than the default one.
  \item
    \label{item:rewrite}
    it defines a \texttt{@rewrite} macro that rewrites an expression using the standard operations (e.g \texttt{+}, \texttt{*}, ...) into an expression that exploits the mutability of the intermediate values created when evalutating the expression.
\end{enumerate}

JuMP~\cite{dunning2017jump} used to have its own API for mutable operations on JuMP expressions and
its own JuMP-specific implementation of \ref{item:reimplement} and \ref{item:rewrite}.
These two features are one of the key reasons why JuMP is competitive in performance with commercial algebraic modeling languages~\cite[Section~3--4]{dunning2017jump}.
These features were refactored into MA, generalizing them to arbitrary mutable types.
Starting from JuMP v0.21, JuMP expression and MOI functions implement the MutableArithmetics API, and
the JuMP-specific implementations of \ref{item:reimplement} and \ref{item:rewrite} were replaced by the generic versions implemented in MA on top of the MA API.

\section{Design consideration}
This section provides concrete examples that motivated the design of MA.
The section is organized into four subsections that describe the need of four key features of MA's API.

\subsection{May mutate}
Consider the task of summing the elements of a vector.
By default, Julia \texttt{sum} function will compute with a code equivalent to the following:
\begin{lstlisting}[language = Julia]
function sum(x::Vector)
    acc = zero(eltype(x))
    for el in x
        acc = acc + el
    end
    return acc
end
\end{lstlisting}
If the type of the elements of \texttt{x} is \texttt{BigInt}, it is more efficient to replace the line
\lstinline|acc = acc + el| by the line
\lstinline|Base.GMP.MPZ.add!(acc, el)|.
Indeed, as the operation \lstinline|+| cannot modify its arguments,
it will need to allocate a new instance of \texttt{BigInt} to contain the result.
On the other hand, \lstinline|Base.GMP.MPZ.add!| modifies \lstinline|acc| in place to contain the result.

Even if using \lstinline|Base.GMP.MPZ.add!| provides a significant performance improvement,
the time complexity is identical.
We now consider a mutable element type for which exploiting mutability affects the time complexity.
Consider a type \texttt|SymolicVariable| representing a symbolic variable and the following types representing a linear combinations of these variables with coefficients of type \texttt|T|.
This is examples encapsulates for instance JuMP affine expressions~\cite{dunning2017jump}, MOI affine functions~\cite{legat2021mathoptinterface}, polynomials (univariate~\cite{verzani2021polynomials} or multivariate~\cite{legat2021multivariatepolynomials}) or symbolic sum~\cite{gowda2021high}.
\begin{lstlisting}[language = Julia]
struct Term{T}
    coef::T
    sym::SymbolicVariable
end
struct Sum{T}
    terms::Vector{Term{T}}
end
Base.:+(s::Sum, t::Term) = Sum(push!(copy(s.terms), t))
Base.zero(::Type{Term{T}}) where {T} = Sum(Term{T}[])
\end{lstlisting}
Calling \texttt{sum} on a vector of $n$ \texttt{Term{T}} has a time complexity $\Theta(n^2)$.
Indeed, when calling \lstinline|acc + el| where \lstinline|acc| contains the sum of the first \lstinline|k| terms and \lstinline|el| is the $(k+1)$th term,
the result cannot mutate \lstinline|acc.terms| and the copy of \lstinline|acc.terms| has time complexity $\Theta(k)$.

A possible mutable interface would be to define an \lstinline|add!| function
that is similar to \lstinline|+| with the only difference being that it
is allowed to modify its first argument.
By default, \lstinline|add!| would fall back to calling \lstinline|+|
so that a method calling \lstinline|add!| would both exploit the mutability
of mutable types but would also work for non-mutable types.
For our example, an implementation could be:
\begin{lstlisting}[language = Julia]
function sum(x)
    acc = zero(eltype(x))
    for el in x
        acc = MA.add!(acc, el)
    end
    return acc
end
MA.add!(a, b) = a + b # default fallback
MA.add!(a::BigInt, b::BigInt) = Base.GMP.MPZ.add!(a, b)
function MA.add!(s::Sum, t::Term)
    push!(s.terms, t)
    return s
end
\end{lstlisting}
Note that the time complexity of the sum of $n$ \lstinline|Term| is now $\Theta(n)$.

Julia implements a specialized method for computing the sum of \lstinline|BigInt|s that uses \lstinline|Base.GMP.MPZ.add!|.
Similarly, before its version v0.21, JuMP used to implement a specialized method for the sum of JuMP expressions.
The advantage of having a standardized API for mutable addition is that
only one implementation of \lstinline|sum| is needed.
This approach of an API based on a function that may mutate its first argument in order to allow the same code to work both for mutable and non-mutable type is
used by the \lstinline|!!| convention in BangBang~\cite{takafumi2021bangbang},
the mutable API in AbstractAlgebra~\cite{AbstractAlgebra.jl-2017},
as well as the \lstinline|destructive_add!| function in JuMP v0.20.

\subsection{Should mutate}
When writing a code that should mutate the first argument of an operation,
an API that silently returns the result without modifying the first argument is not appropriate.
For this reason, there are also mutable operations that always mutate the first argument.
This is the approach used by the \lstinline|!| convention in Julia
as well as the \lstinline|add_to_expression!| in JuMP.

\subsection{Can mutate?}
A third useful feature for users of a mutable API is the ability to
determine whether objects of a given type can be mutated\footnote{\label{foot:mutate}In this paper, the terminology ``mutate $x$ to $y$'' means mutating $x$ in such a way that its value after the mutation is equal to $y$} to the result of a mutable operation.
To motivate this, consider the rational Julia type:
\begin{lstlisting}[language = Julia]
struct Rational{T}
    num::T
    den::T
end
\end{lstlisting}
An implementation of a multiplication function (ignoring the simplification with \lstinline|gcd| for simplicity) that may
mutate its first argument, say \lstinline|mul!!| to follow BangBang's convention,
could be:
\begin{lstlisting}[language = Julia]
function mul!!(a::Rational{S}, b::Rational{T})
    if # S can be mutated to `*(::S, ::T)`
        mul!(a.num, b.num)
        mul!(a.den, b.den)
        return a
    else
        return a * b
    end
end
\end{lstlisting}
Note \lstinline|a.num = mul!!(a.num, b.num)| is not an option since
the \lstinline|Rational| struct is not mutable.
This third feature would be needed to implement this \lstinline|if| clause.

\subsection{Promotion}
Algorithms that can exploit mutability often start by creating an accumulator of
an appropriate type.
In the example above, \lstinline|sum| start by create the accumulator \lstinline|acc|.
Another example is matrix multiplication which start by allocating the resulting matrix and then mutate\cref{foot:mutate} it to the result with \lstinline|LinearAlgebra.mul!|.
To determine the element type of this resulting array,
LinearAlgebra uses \lstinline|Base.promote_op| which relies on Julia inference.

\section{API}

MutableArithmetics.jl defines the following four functions that provides the features motivated in the corresponding four subsections of the previous section.
\begin{enumerate}
  \item \lstinline|operate!!(op::Function, args...)| (resp. \lstinline|operate_to!!(output, op::Function, args...)|) returns the result of \lstinline|op(args...)| and may mutate \lstinline|args[1]| (resp. \lstinline|output|).
  \item \lstinline|operate!(op::Function, args...)| (resp. \lstinline|operate_to!(output, op::Function, args...)|) mutate\cref{foot:mutate} \lstinline|args[1]| (resp. \lstinline|output|) to the result of \lstinline|op(args...)| and returns it.
  \item \lstinline|mutability(T::Type, op::Function, args::Type...)| returns whether objects of type \lstinline|T| can be mutate to the result of \lstinline|op(::args[1], ::args[2], ...)|.
  \item \lstinline|promote_operation(op::Function, args::Type...)| returns the return type of \lstinline|op(::args[1], ::args[2], ...)|.
\end{enumerate}

As we detailed in the previous section, this API covers many use cases.
The downside of such a varied API is that it seems to be a lot of work to implement it for a mutable type.
We show in the remainder of this section how the MA API remains simple to implement nevertheless.

First, \lstinline|promote_operation| can have default fallback.
For instance, \lstinline|promote_operation(+, ::Type{S}, ::Type{T})|
defaults to \lstinline|typeof(zero(S) + zero(T))| which is correct if \lstinline|+(::S, ::T)| is type-stable.
As the result of \lstinline|promote_operation| only depends on the signature of the function,

There are two cases for which this default implementation of \lstinline|promote_operation| is not sufficient.
As we will see below, \lstinline|promote_operation| is a the core of many operation so it is important that it is efficient.
Julia may be able to compute the result of \lstinline|typeof(zero(S) + zero(T))| at compile time.
However, if the body of \lstinline|promote_operation| is not evaluated at compile-time, this can cause performance issue.
This is amplified for mutable types as \lstinline|zero(S) + zero(T)| may allocate.
Moreover, if \lstinline|zero(S) + zero(T)| ends up calling \lstinline|promote_operation(+, S, T)|, this default implementation will not terminate.
In both of these cases, \lstinline|promote_operation| should have a specialized implementation, e.g., by hardcoding the result for each pairs of concrete types \lstinline|S| and \lstinline|T|.
Note that implementing \lstinline|promote_operation| should be easier than implementing the actual operation where the actual value of the result need to be computed, not just the type so this should not consitute a burden for the implementation.

We have the following default implementations of \lstinline|operate!!| (resp. \lstinline|operate_to!!|) that should be correct in all cases and have optimal performance in case the trait \lstinline|mutability| is optimized out by the compiler.
Indeed, as the functions \lstinline|op| and \lstinline|operate!(op, ...)| (resp. \lstinline|operate_to!(op, ...)|) are strictly more specific than \lstinline|operate!!| (resp. \lstinline|operate_to!!|),
if the run-time cost of the trait \lstinline|mutability| is zero,
if a specialized method is faster than this implementation,
it means that either
\lstinline|op| or \lstinline|operate!(op, ...)| (resp. \lstinline|operate_to!(op, ...)|)
can be implemented more efficiently.
\begin{lstlisting}[language = Julia]
function operate!!(op, args...)
    T = typeof.(args)
    if mutability(T[1], op, T...) isa Mutable
        return operate!(op, args...)
    else
        return op(args...)
    end
end
function operate_to!!(output, op, args...)
    O = typeof(output)
    T = typeof.(args)
    if mutability(O, op, T...) isa Mutable
        return operate_to!(output, op, args...)
    else
        return op(args...)
    end
end
\end{lstlisting}

It turns out that all type considered at the moment fall into two categories.
The first category are the types \lstinline|T| for which
\lstinline|mutability(T, ...)| always return \lstinline|NotMutable()|.
These are typically the non-mutable type, e.g., \lstinline|Int|, \lstinline|Float64|, \lstinline|Rational{Int}|, ...
In the second category are the types \lstinline|T| for which
\lstinline|mutability(T, op, args...)| returns \lstinline|Mutable()|
if and only if \lstinline|T == promote_operation(op, args...)|.
Based on this observation, we define \lstinline|mutability(T::Type)| which
returns \lstinline|Mutable()| if \lstinline|T| is in the first category
and \lstinline|NotMutable()| if \lstinline|T| is in the second category.
Then we have the following fallback for \lstinline|mutability|:
\begin{lstlisting}[language = Julia]
function mutability(T::Type, op::Function, args::Type...)
    if mutability(T) isa Mutable &&
        T == promote_operation(op, args...)
        return Mutable()
    else
        return NotMutable()
    end
end
\end{lstlisting}

\input{bib.tex}

\end{document}
